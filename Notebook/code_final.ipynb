{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Anime-PlanetID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Alternative Name</th>\n",
       "      <th>Rating Score</th>\n",
       "      <th>Number Votes</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Content Warning</th>\n",
       "      <th>Type</th>\n",
       "      <th>Episodes</th>\n",
       "      <th>Finished</th>\n",
       "      <th>Duration</th>\n",
       "      <th>StartYear</th>\n",
       "      <th>EndYear</th>\n",
       "      <th>Season</th>\n",
       "      <th>Studios</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>The Prince of Tennis</td>\n",
       "      <td>Tennis no Ouji-sama</td>\n",
       "      <td>4.037</td>\n",
       "      <td>10889</td>\n",
       "      <td>Comedy, Drama, Shounen, Sports, Tennis, Based ...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>TV</td>\n",
       "      <td>178</td>\n",
       "      <td>True</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2001</td>\n",
       "      <td>2005</td>\n",
       "      <td>Fall 2001</td>\n",
       "      <td>Production I.G, Trans Arts</td>\n",
       "      <td>Meet Ryoma Echizen, the cocky prince of tennis...</td>\n",
       "      <td>https://www.anime-planet.com/anime/the-prince-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>Neon Genesis Evangelion</td>\n",
       "      <td>Shinseiki Evangelion</td>\n",
       "      <td>4.248</td>\n",
       "      <td>54463</td>\n",
       "      <td>Drama, Mecha, Sci Fi, Conspiracy, Kaijuu, Lone...</td>\n",
       "      <td>Emotional Abuse, Explicit Violence, Mature The...</td>\n",
       "      <td>TV</td>\n",
       "      <td>26</td>\n",
       "      <td>True</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1995</td>\n",
       "      <td>1996</td>\n",
       "      <td>Fall 1995</td>\n",
       "      <td>GAINAX, Tatsunoko Production</td>\n",
       "      <td>In the future, a devastating event known as Se...</td>\n",
       "      <td>https://www.anime-planet.com/anime/neon-genesi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>Full Metal Panic! The Second Raid</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>4.35</td>\n",
       "      <td>23948</td>\n",
       "      <td>Action, Comedy, Mecha, Sci Fi, Shounen, Milita...</td>\n",
       "      <td>Explicit Violence, Nudity</td>\n",
       "      <td>TV</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005</td>\n",
       "      <td>Summer 2005</td>\n",
       "      <td>Kyoto Animation</td>\n",
       "      <td>Half a year has passed since Sousuke Sagara to...</td>\n",
       "      <td>https://www.anime-planet.com/anime/full-metal-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>22/7: Shampoo no Nioi ga Shita</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2.8</td>\n",
       "      <td>131</td>\n",
       "      <td>Idols, School Life, CG Animation</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Music</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The idol group 22/7 perform the song Shampoo n...</td>\n",
       "      <td>https://www.anime-planet.com/anime/22-7-shampo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10001</td>\n",
       "      <td>Oshiri Tantei: Puputto Fumutto Kaiketsu Dance</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1.271</td>\n",
       "      <td>21</td>\n",
       "      <td>Family Friendly</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Web</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Toei Animation</td>\n",
       "      <td>No synopsis yet - check back soon!</td>\n",
       "      <td>https://www.anime-planet.com/anime/oshiri-tant...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Anime-PlanetID                                           Name  \\\n",
       "0      0              10                           The Prince of Tennis   \n",
       "1      1             100                        Neon Genesis Evangelion   \n",
       "2      2            1000              Full Metal Panic! The Second Raid   \n",
       "3      3           10000                 22/7: Shampoo no Nioi ga Shita   \n",
       "4      4           10001  Oshiri Tantei: Puputto Fumutto Kaiketsu Dance   \n",
       "\n",
       "       Alternative Name Rating Score Number Votes  \\\n",
       "0   Tennis no Ouji-sama        4.037        10889   \n",
       "1  Shinseiki Evangelion        4.248        54463   \n",
       "2               Unknown         4.35        23948   \n",
       "3               Unknown          2.8          131   \n",
       "4               Unknown        1.271           21   \n",
       "\n",
       "                                                Tags  \\\n",
       "0  Comedy, Drama, Shounen, Sports, Tennis, Based ...   \n",
       "1  Drama, Mecha, Sci Fi, Conspiracy, Kaijuu, Lone...   \n",
       "2  Action, Comedy, Mecha, Sci Fi, Shounen, Milita...   \n",
       "3                   Idols, School Life, CG Animation   \n",
       "4                                    Family Friendly   \n",
       "\n",
       "                                     Content Warning   Type Episodes  \\\n",
       "0                                            Unknown     TV      178   \n",
       "1  Emotional Abuse, Explicit Violence, Mature The...     TV       26   \n",
       "2                          Explicit Violence, Nudity     TV       13   \n",
       "3                                            Unknown  Music        1   \n",
       "4                                            Unknown    Web        1   \n",
       "\n",
       "   Finished Duration StartYear EndYear       Season  \\\n",
       "0      True  Unknown      2001    2005    Fall 2001   \n",
       "1      True  Unknown      1995    1996    Fall 1995   \n",
       "2      True  Unknown      2005    2005  Summer 2005   \n",
       "3      True        5      2018    2018      Unknown   \n",
       "4      True        2      2017    2017      Unknown   \n",
       "\n",
       "                        Studios  \\\n",
       "0    Production I.G, Trans Arts   \n",
       "1  GAINAX, Tatsunoko Production   \n",
       "2               Kyoto Animation   \n",
       "3                       Unknown   \n",
       "4                Toei Animation   \n",
       "\n",
       "                                            Synopsis  \\\n",
       "0  Meet Ryoma Echizen, the cocky prince of tennis...   \n",
       "1  In the future, a devastating event known as Se...   \n",
       "2  Half a year has passed since Sousuke Sagara to...   \n",
       "3  The idol group 22/7 perform the song Shampoo n...   \n",
       "4                 No synopsis yet - check back soon!   \n",
       "\n",
       "                                                 Url  \n",
       "0  https://www.anime-planet.com/anime/the-prince-...  \n",
       "1  https://www.anime-planet.com/anime/neon-genesi...  \n",
       "2  https://www.anime-planet.com/anime/full-metal-...  \n",
       "3  https://www.anime-planet.com/anime/22-7-shampo...  \n",
       "4  https://www.anime-planet.com/anime/oshiri-tant...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:/College/sem 7/final year project/gith/AniSearch/anime.csv')\n",
    "df = df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Anime-PlanetID', 'Name', 'Alternative Name', 'Rating Score',\n",
       "       'Number Votes', 'Tags', 'Content Warning', 'Type', 'Episodes',\n",
       "       'Finished', 'Duration', 'StartYear', 'EndYear', 'Season', 'Studios',\n",
       "       'Synopsis', 'Url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Load the CSV file\n",
    "# # data = pd.read_csv('path to csv')  # Replace with your actual file name\n",
    "\n",
    "# # Drop rows with missing values\n",
    "# data = df\n",
    "# data = data.dropna()\n",
    "\n",
    "# # Convert 'Rating Score' to float and drop rows with invalid scores\n",
    "# data['Rating Score'] = pd.to_numeric(data['Rating Score'], errors='coerce')\n",
    "# data = data.dropna(subset=['Rating Score'])\n",
    "\n",
    "# # Sort the anime by 'Rating Score' in descending order and select the top 10\n",
    "# top_anime = data.sort_values(by='Rating Score', ascending=False).head(10)\n",
    "\n",
    "# # Debugging: Print the top 10 data to ensure it's populated\n",
    "# print(top_anime)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting top 10 anime of all time (based on Rating-Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting with Seaborn\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# sns.barplot(data=top_anime, x='Rating Score', y='Name', palette='plasma')  # Use DataFrame columns directly\n",
    "# plt.xlabel('Rating Score')\n",
    "# plt.ylabel('Anime Name')\n",
    "# plt.title('Top 10 Anime by Rating Score')\n",
    "\n",
    "# # Set x-axis ticks and labels from 4.5 to 4.7 with a gap of 0.05\n",
    "# plt.xticks(ticks=[x * 0.05 + 4.5 for x in range(5)], labels=[f'{x * 0.05 + 4.5:.2f}' for x in range(5)])\n",
    "\n",
    "# # Set x-axis limits from 4.5 to 4.7\n",
    "# plt.xlim(4.5, 4.75)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Rating Score','Number Votes','Studios','Synopsis', 'Tags', 'Episodes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_features(row):\n",
    "    return str(row[\"Rating Score\"])+\" \"+ str(row[\"Number Votes\"])+\" \"+ str(row[\"Studios\"])+\" \"+ str(row[\"Synopsis\"])+\" \"+ str(row[\"Tags\"])+\" \"+ str(row[\"Episodes\"])+\" \"\n",
    "\n",
    "def get_title_from_index(index):\n",
    "    return df[df[\"index\"] == index][\"Name\"].values[0]\n",
    "def get_index_from_title(title):\n",
    "    return df[df[\"Name\"] == title][\"index\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.037 10889 Production I.G, Trans Arts Meet Ry...\n",
       "1    4.248 54463 GAINAX, Tatsunoko Production In th...\n",
       "2    4.35 23948 Kyoto Animation Half a year has pas...\n",
       "3    2.8 131 Unknown The idol group 22/7 perform th...\n",
       "4    1.271 21 Toei Animation No synopsis yet - chec...\n",
       "Name: combined_feature, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"combined_feature\"]=df.apply(combined_features,axis=1)\n",
    "df[\"combined_feature\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the dataset\n",
    "# # data = pd.read_csv('..\\\\anime.csv')  \n",
    "# data=df\n",
    "\n",
    "# # Drop rows with NaN values\n",
    "# data_cleaned = data.dropna()\n",
    "\n",
    "# # Replace 'unknown' values with NaN and drop them\n",
    "# data_cleaned = data_cleaned.replace('unknown', pd.NA).dropna()\n",
    "\n",
    "# # Print the number of remaining data points\n",
    "# print(\"Remaining data points:\", len(data_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "count_matrix=cv.fit_transform(df[\"combined_feature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_liked = \"One-piece\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one piece\n",
      "one piece recap\n",
      "princess mononoke\n",
      "one piece movie 10: strong world\n",
      "one piece: dream soccer king!\n",
      "one piece movie 9: episode of chopper - the miracle winter cherry blossom\n",
      "sekai meisaku douwa: aladdin to mahou no lamp\n",
      "nura: rise of the youkai clan\n",
      "nodame cantabile: special lesson\n",
      "b-legend! battle b-daman\n",
      "arion\n",
      "pokemon movie 2: the power of one\n",
      "the faraway paladin\n",
      "hunter x hunter: jump super anime tour 1998\n",
      "arata the legend\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(count_matrix)\n",
    "from difflib import get_close_matches\n",
    "\n",
    "\n",
    "def get_index_from_title(title):\n",
    "    title = title.strip().lower()\n",
    "    df[\"Name\"] = df[\"Name\"].str.strip().str.lower()\n",
    "    matches = get_close_matches(title, df[\"Name\"], n=1, cutoff=0.8)  \n",
    "    if matches:\n",
    "        title = matches[0]  \n",
    "        return df[df[\"Name\"] == title][\"index\"].values[0]\n",
    "    else:\n",
    "        raise ValueError(f\"No close matches found for '{title}'.\")\n",
    "\n",
    "try:\n",
    "    liked_movie_index = cosine_sim[get_index_from_title(anime_liked)]\n",
    "    similar_anime = list(enumerate(liked_movie_index))\n",
    "    similar_anime.sort(key=lambda row: row[1], reverse=True)\n",
    "    for i in range(15):\n",
    "        print(get_title_from_index(similar_anime[i][0]))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendation using Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from difflib import get_close_matches\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score, mean_absolute_error\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# def get_index_from_title(title):\n",
    "#     title = title.strip().lower()\n",
    "#     df[\"Name\"] = df[\"Name\"].str.strip().str.lower()\n",
    "#     matches = get_close_matches(title, df[\"Name\"], n=1, cutoff=0.8)  \n",
    "#     if matches:\n",
    "#         title = matches[0]  \n",
    "#         return df[df[\"Name\"] == title][\"index\"].values[0]\n",
    "#     else:\n",
    "#         raise ValueError(f\"No close matches found for '{title}'.\")\n",
    "\n",
    "# df['Rating Score'] = pd.to_numeric(df['Rating Score'], errors='coerce')\n",
    "# df['Number Votes'] = pd.to_numeric(df['Number Votes'], errors='coerce')\n",
    "\n",
    "# train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# try:\n",
    "    \n",
    "#     y_true = []\n",
    "#     y_pred = []\n",
    "#     mae_scores = []\n",
    "    \n",
    "#     for idx, row in test_df.iterrows():\n",
    "#         true_rating = row['Rating Score']\n",
    "#         anime_name = row['Name']\n",
    "        \n",
    "#         liked_movie_index = cosine_sim[get_index_from_title(anime_name)]\n",
    "#         similar_anime = list(enumerate(liked_movie_index))\n",
    "#         similar_anime.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "#         recommended_indices = [x[0] for x in similar_anime[1:31]]  \n",
    "        \n",
    "#         pred_ratings = df.iloc[recommended_indices]['Rating Score'].mean()\n",
    "        \n",
    "#         y_true.append(1 if true_rating >= 4.0 else 0)\n",
    "#         y_pred.append(1 if pred_ratings >= 4.0 else 0)\n",
    "        \n",
    "#         mae_scores.append(abs(true_rating - pred_ratings))\n",
    "        \n",
    "    \n",
    "#     precision = precision_score(y_true, y_pred)\n",
    "#     recall = recall_score(y_true, y_pred)\n",
    "#     f1 = f1_score(y_true, y_pred)\n",
    "#     mae = np.mean(mae_scores)\n",
    "    \n",
    "#     print(f\"\\nRecommendations for {anime_liked} (Cosine Similarity):\")\n",
    "#     liked_movie_index = cosine_sim[get_index_from_title(anime_liked)]\n",
    "#     similar_anime = list(enumerate(liked_movie_index))\n",
    "#     similar_anime.sort(key=lambda row: row[1], reverse=True)\n",
    "#     for i in range(15):\n",
    "#         print(get_title_from_index(similar_anime[i][0]))\n",
    "        \n",
    "#     print(\"\\n\")\n",
    "#     print()\n",
    "    \n",
    "#     print(f\"Precision: {precision:.3f}\")\n",
    "#     print(f\"Recall: {recall:.3f}\")\n",
    "#     print(f\"F1 Score: {f1:.3f}\")\n",
    "#     print(f\"Mean Absolute Error: {mae:.3f}\")\n",
    "    \n",
    "        \n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Fill NaN values with empty strings\n",
    "# df['Tags'] = df['Tags'].fillna('')\n",
    "# df['Studios'] = df['Studios'].fillna('')\n",
    "# df['Type'] = df['Type'].fillna('Unknown')\n",
    "# df['Synopsis'] = df['Synopsis'].fillna('')  # Ensure no NaN values in synopsis\n",
    "\n",
    "# # Convert 'Number Votes' to numeric and scale it\n",
    "# df['Number Votes'] = pd.to_numeric(df['Number Votes'], errors='coerce').fillna(0)\n",
    "# scaler = StandardScaler()\n",
    "# scaled_votes = scaler.fit_transform(df[['Number Votes']])\n",
    "\n",
    "# # TF-IDF Vectorization for Tags\n",
    "# tag_vectorizer = TfidfVectorizer(stop_words='english', max_features=600)\n",
    "# tag_matrix = tag_vectorizer.fit_transform(df['Tags']).toarray()\n",
    "\n",
    "# # TF-IDF Vectorization for Synopsis\n",
    "# synopsis_vectorizer = TfidfVectorizer(stop_words='english', max_features=1500)  # More features for better representation\n",
    "# synopsis_matrix = synopsis_vectorizer.fit_transform(df['Synopsis']).toarray()\n",
    "\n",
    "# # One-Hot Encoding for Studios and Type\n",
    "# encoder = OneHotEncoder()\n",
    "# studios_encoded = encoder.fit_transform(df[['Studios']]).toarray()\n",
    "# type_encoded = encoder.fit_transform(df[['Type']]).toarray()\n",
    "\n",
    "# # Combine all features\n",
    "# features_combined = np.hstack([scaled_votes, tag_matrix, synopsis_matrix, studios_encoded, type_encoded])\n",
    "\n",
    "# print(\"Feature matrix shape:\", features_combined.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations for One-piece (Cosine Similarity):\n",
      "one piece\n",
      "one piece recap\n",
      "princess mononoke\n",
      "one piece movie 10: strong world\n",
      "one piece: dream soccer king!\n",
      "one piece movie 9: episode of chopper - the miracle winter cherry blossom\n",
      "sekai meisaku douwa: aladdin to mahou no lamp\n",
      "nura: rise of the youkai clan\n",
      "nodame cantabile: special lesson\n",
      "b-legend! battle b-daman\n",
      "arion\n",
      "pokemon movie 2: the power of one\n",
      "the faraway paladin\n",
      "hunter x hunter: jump super anime tour 1998\n",
      "arata the legend\n",
      "Feature matrix shape: (16621, 3153)\n"
     ]
    }
   ],
   "source": [
    "from difflib import get_close_matches\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load and clean data\n",
    "df['Tags'] = df['Tags'].fillna('')\n",
    "df['Studios'] = df['Studios'].fillna('')\n",
    "df['Type'] = df['Type'].fillna('Unknown')\n",
    "df['Synopsis'] = df['Synopsis'].fillna('')\n",
    "df['Rating Score'] = pd.to_numeric(df['Rating Score'], errors='coerce')\n",
    "df['Number Votes'] = pd.to_numeric(df['Number Votes'], errors='coerce').fillna(0)\n",
    "\n",
    "# Preprocessing\n",
    "scaler = StandardScaler()\n",
    "scaled_votes = scaler.fit_transform(df[['Number Votes']])\n",
    "\n",
    "tag_vectorizer = TfidfVectorizer(stop_words='english', max_features=600)\n",
    "tag_matrix = tag_vectorizer.fit_transform(df['Tags']).toarray()\n",
    "\n",
    "synopsis_vectorizer = TfidfVectorizer(stop_words='english', max_features=1500)\n",
    "synopsis_matrix = synopsis_vectorizer.fit_transform(df['Synopsis']).toarray()\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "studios_encoded = encoder.fit_transform(df[['Studios']]).toarray()\n",
    "type_encoded = encoder.fit_transform(df[['Type']]).toarray()\n",
    "\n",
    "\n",
    "\n",
    "# Recommendation helper functions\n",
    "def get_index_from_title(title):\n",
    "    title = title.strip().lower()\n",
    "    df[\"Name\"] = df[\"Name\"].str.strip().str.lower()\n",
    "    matches = get_close_matches(title, df[\"Name\"], n=1, cutoff=0.8)\n",
    "    if matches:\n",
    "        title = matches[0]\n",
    "        return df[df[\"Name\"] == title][\"index\"].values[0]\n",
    "    else:\n",
    "        raise ValueError(f\"No close matches found for '{title}'.\")\n",
    "\n",
    "def get_title_from_index(index):\n",
    "    return df[df.index == index][\"Name\"].values[0]\n",
    "\n",
    "# Example recommendation (requires cosine_sim to be defined elsewhere)\n",
    "try:\n",
    "    # anime_liked = \"Naruto\"  # Example input\n",
    "    liked_movie_index = cosine_sim[get_index_from_title(anime_liked)]\n",
    "    similar_anime = list(enumerate(liked_movie_index))\n",
    "    similar_anime.sort(key=lambda row: row[1], reverse=True)\n",
    "\n",
    "    print(f\"\\nRecommendations for {anime_liked} (Cosine Similarity):\")\n",
    "    for i in range(15):\n",
    "        print(get_title_from_index(similar_anime[i][0]))\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "features_combined = np.hstack([scaled_votes, tag_matrix, synopsis_matrix, studios_encoded, type_encoded])\n",
    "print(\"Feature matrix shape:\", features_combined.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendation using k-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score, mean_absolute_error\n",
    "\n",
    "# # Perform KMeans\n",
    "# kmeans = KMeans(n_clusters=20, random_state=42)\n",
    "# clusters = kmeans.fit_predict(features_combined)\n",
    "\n",
    "# df['KMeans_Cluster'] = clusters\n",
    "\n",
    "# def recommend_anime_kmeans(title, top_n=10):\n",
    "#     anime_index = get_index_from_title(title)\n",
    "#     anime_cluster = df.loc[anime_index, 'KMeans_Cluster']\n",
    "    \n",
    "#     similar_anime = df[df['KMeans_Cluster'] == anime_cluster]\n",
    "    \n",
    "#     recommended_anime = similar_anime[similar_anime['Name'] != title].head(top_n)['Name'].values\n",
    "#     return recommended_anime\n",
    "\n",
    "# recommended_anime_kmeans = recommend_anime_kmeans(anime_liked)\n",
    "# print(f\"Anime similar to '{anime_liked}' based on KMeans clustering:\")\n",
    "# for anime in recommended_anime_kmeans:\n",
    "#     print(anime)\n",
    "\n",
    "# true_labels = (df['KMeans_Cluster'] == df.loc[get_index_from_title(anime_liked), 'KMeans_Cluster']).astype(int)\n",
    "# pred_labels = np.zeros(len(df))\n",
    "# recommended_indices = [get_index_from_title(anime) for anime in recommended_anime_kmeans]\n",
    "# pred_labels[recommended_indices] = 1\n",
    "\n",
    "# precision = precision_score(true_labels, pred_labels)\n",
    "# recall = recall_score(true_labels, pred_labels)\n",
    "# f1 = f1_score(true_labels, pred_labels)\n",
    "# df['Rating Score'] = pd.to_numeric(df['Rating Score'].replace('Unknown', np.nan), errors='coerce')\n",
    "# df['Rating Score'] = df['Rating Score'].fillna(df['Rating Score'].mean())\n",
    "\n",
    "# true_ratings = df['Rating Score'].values\n",
    "# pred_ratings = np.zeros(len(df))\n",
    "# pred_ratings[recommended_indices] = df.loc[get_index_from_title(anime_liked), 'Rating Score']\n",
    "# mae = mean_absolute_error(true_ratings, pred_ratings)\n",
    "\n",
    "# print(\"\\nMetrics:\")\n",
    "# print(f\"Precision: {precision:.3f}\")\n",
    "# print(f\"Recall: {recall:.3f}\")\n",
    "# print(f\"F1 Score: {f1:.3f}\")\n",
    "# print(f\"Mean Absolute Error: {mae:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendation using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score, mean_absolute_error\n",
    "\n",
    "# knn = NearestNeighbors(n_neighbors=11, metric='cosine')  \n",
    "# knn.fit(features_combined)\n",
    "\n",
    "# # Function to recommend based on KNN\n",
    "# def recommend_anime_knn(title, top_n=10):\n",
    "#     anime_index = get_index_from_title(title)\n",
    "    \n",
    "#     distances, indices = knn.kneighbors(features_combined[anime_index].reshape(1, -1))\n",
    "    \n",
    "#     recommended_anime = df.iloc[indices[0][1:top_n+1]]['Name'].values\n",
    "#     return recommended_anime\n",
    "\n",
    "# recommended_anime_knn = recommend_anime_knn(anime_liked)\n",
    "# print(f\"Anime similar to '{anime_liked}' based on KNN:\")\n",
    "# for anime in recommended_anime_knn:\n",
    "#     print(anime)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN using Cosine-Sim (without normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anime similar to 'One-piece' based on Cosine Similarity:\n",
      "\n",
      "one piece                                                                  |  Distance: 0.0000  |  Similarity: 1.0000\n",
      "one piece recap                                                            |  Distance: 0.3074  |  Similarity: 0.6926\n",
      "princess mononoke                                                          |  Distance: 0.3154  |  Similarity: 0.6846\n",
      "one piece movie 10: strong world                                           |  Distance: 0.3224  |  Similarity: 0.6776\n",
      "one piece: dream soccer king!                                              |  Distance: 0.3255  |  Similarity: 0.6745\n",
      "one piece movie 9: episode of chopper - the miracle winter cherry blossom  |  Distance: 0.3264  |  Similarity: 0.6736\n",
      "sekai meisaku douwa: aladdin to mahou no lamp                              |  Distance: 0.3311  |  Similarity: 0.6689\n",
      "nura: rise of the youkai clan                                              |  Distance: 0.3334  |  Similarity: 0.6666\n",
      "nodame cantabile: special lesson                                           |  Distance: 0.3338  |  Similarity: 0.6662\n",
      "b-legend! battle b-daman                                                   |  Distance: 0.3378  |  Similarity: 0.6622\n",
      "arion                                                                      |  Distance: 0.3386  |  Similarity: 0.6614\n",
      "pokemon movie 2: the power of one                                          |  Distance: 0.3398  |  Similarity: 0.6602\n",
      "the faraway paladin                                                        |  Distance: 0.3401  |  Similarity: 0.6599\n",
      "hunter x hunter: jump super anime tour 1998                                |  Distance: 0.3428  |  Similarity: 0.6572\n",
      "arata the legend                                                           |  Distance: 0.3431  |  Similarity: 0.6569\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(count_matrix)\n",
    "from difflib import get_close_matches\n",
    "\n",
    "def get_index_from_title(title):\n",
    "    title = title.strip().lower()\n",
    "    df[\"Name\"] = df[\"Name\"].str.strip().str.lower()\n",
    "    matches = get_close_matches(title, df[\"Name\"], n=1, cutoff=0.8)  \n",
    "    if matches:\n",
    "        title = matches[0]  \n",
    "        return df[df[\"Name\"] == title][\"index\"].values[0]\n",
    "    else:\n",
    "        raise ValueError(f\"No close matches found for '{title}'.\")\n",
    "\n",
    "try:\n",
    "    liked_movie_index = get_index_from_title(anime_liked)\n",
    "    similarity_scores = cosine_sim[liked_movie_index] \n",
    "    # Get similarity scores for the liked anime\n",
    "    similar_anime = list(enumerate(similarity_scores)) \n",
    "    similar_anime.sort(key=lambda row: row[1], reverse=True)  # Sort by similarity score (highest first)\n",
    "\n",
    "    print(f\"Anime similar to '{anime_liked}' based on Cosine Similarity:\\n\")\n",
    "\n",
    "    max_name_length = max(len(get_title_from_index(anime[0])) for anime in similar_anime[:15])  # Find longest name\n",
    "\n",
    "    for i in range(15):\n",
    "        anime_name = get_title_from_index(similar_anime[i][0])\n",
    "        similarity_score = similar_anime[i][1]\n",
    "        distance = 1 - similarity_score  # Cosine distance\n",
    "\n",
    "        print(f\"{anime_name.ljust(max_name_length)}  |  Distance: {distance:.4f}  |  Similarity: {similarity_score:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anime similar to 'One-piece' based on Cosine Similarity:\n",
      "\n",
      "one piece                                                                  |  Distance: 1.0000  |  Similarity: 0.0000\n",
      "one piece recap                                                            |  Distance: 0.6926  |  Similarity: 0.3074\n",
      "princess mononoke                                                          |  Distance: 0.6846  |  Similarity: 0.3154\n",
      "one piece movie 10: strong world                                           |  Distance: 0.6776  |  Similarity: 0.3224\n",
      "one piece: dream soccer king!                                              |  Distance: 0.6745  |  Similarity: 0.3255\n",
      "one piece movie 9: episode of chopper - the miracle winter cherry blossom  |  Distance: 0.6736  |  Similarity: 0.3264\n",
      "sekai meisaku douwa: aladdin to mahou no lamp                              |  Distance: 0.6689  |  Similarity: 0.3311\n",
      "nura: rise of the youkai clan                                              |  Distance: 0.6666  |  Similarity: 0.3334\n",
      "nodame cantabile: special lesson                                           |  Distance: 0.6662  |  Similarity: 0.3338\n",
      "b-legend! battle b-daman                                                   |  Distance: 0.6622  |  Similarity: 0.3378\n",
      "arion                                                                      |  Distance: 0.6614  |  Similarity: 0.3386\n",
      "pokemon movie 2: the power of one                                          |  Distance: 0.6602  |  Similarity: 0.3398\n",
      "the faraway paladin                                                        |  Distance: 0.6599  |  Similarity: 0.3401\n",
      "hunter x hunter: jump super anime tour 1998                                |  Distance: 0.6572  |  Similarity: 0.3428\n",
      "arata the legend                                                           |  Distance: 0.6569  |  Similarity: 0.3431\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(count_matrix)\n",
    "from difflib import get_close_matches\n",
    "\n",
    "def get_index_from_title(title):\n",
    "    title = title.strip().lower()\n",
    "    df[\"Name\"] = df[\"Name\"].str.strip().str.lower()\n",
    "    matches = get_close_matches(title, df[\"Name\"], n=1, cutoff=0.8)  \n",
    "    if matches:\n",
    "        title = matches[0]  \n",
    "        return df[df[\"Name\"] == title][\"index\"].values[0]\n",
    "    else:\n",
    "        raise ValueError(f\"No close matches found for '{title}'.\")\n",
    "\n",
    "try:\n",
    "    liked_movie_index = get_index_from_title(anime_liked)\n",
    "    similarity_scores = cosine_sim[liked_movie_index] \n",
    "    min_distance = np.min(similarity_scores)\n",
    "    max_distance = np.max(similarity_scores)\n",
    "    # Get similarity scores for the liked anime\n",
    "    similar_anime = list(enumerate(similarity_scores)) \n",
    "    similar_anime.sort(key=lambda row: row[1], reverse=True)  # Sort by similarity score (highest first)\n",
    "\n",
    "    print(f\"Anime similar to '{anime_liked}' based on Cosine Similarity:\\n\")\n",
    "\n",
    "    max_name_length = max(len(get_title_from_index(anime[0])) for anime in similar_anime[:15])  # Find longest name\n",
    "\n",
    "    for i in range(15):\n",
    "        anime_name = get_title_from_index(similar_anime[i][0])\n",
    "        raw_distance = similar_anime[i][1]\n",
    "        normalized_distance = (raw_distance - min_distance) / (max_distance - min_distance)\n",
    "        normalized_similarity = 1 - normalized_distance # Cosine distance\n",
    "\n",
    "        print(f\"{anime_name.ljust(max_name_length)}  |  Distance: {normalized_distance:.4f}  |  Similarity: {normalized_similarity:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN using Manhattan (without normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anime similar to 'One-piece' based on Manhattan Distance:\n",
      "\n",
      "one piece - \t\tDistance: 0.0000, \t\tSimilarity: 1.0000\n",
      "dragon ball z - \t\tDistance: 14.6124, \t\tSimilarity: 0.0641\n",
      "hunter x hunter (2011) - \t\tDistance: 14.7766, \t\tSimilarity: 0.0634\n",
      "dragon ball - \t\tDistance: 16.3127, \t\tSimilarity: 0.0578\n",
      "my hero academia 3 - \t\tDistance: 16.3889, \t\tSimilarity: 0.0575\n",
      "soul eater - \t\tDistance: 16.4885, \t\tSimilarity: 0.0572\n",
      "my hero academia 2 - \t\tDistance: 16.5414, \t\tSimilarity: 0.0570\n",
      "angel beats! - \t\tDistance: 17.5059, \t\tSimilarity: 0.0540\n",
      "fairy tail - \t\tDistance: 18.1019, \t\tSimilarity: 0.0524\n",
      "my hero academia - \t\tDistance: 18.1336, \t\tSimilarity: 0.0523\n",
      "tokyo ghoul - \t\tDistance: 18.2414, \t\tSimilarity: 0.0520\n",
      "highschool of the dead - \t\tDistance: 18.2630, \t\tSimilarity: 0.0519\n",
      "blue exorcist - \t\tDistance: 18.2805, \t\tSimilarity: 0.0519\n",
      "demon slayer: kimetsu no yaiba - \t\tDistance: 18.2937, \t\tSimilarity: 0.0518\n",
      "trigun - \t\tDistance: 18.6368, \t\tSimilarity: 0.0509\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from difflib import get_close_matches\n",
    "\n",
    "def get_index_from_title(title):\n",
    "    title = title.strip().lower()\n",
    "    df[\"Name\"] = df[\"Name\"].str.strip().str.lower()\n",
    "    matches = get_close_matches(title, df[\"Name\"], n=1, cutoff=0.8)  \n",
    "    if matches:\n",
    "        title = matches[0]  \n",
    "        return df[df[\"Name\"] == title][\"index\"].values[0]\n",
    "    else:\n",
    "        raise ValueError(f\"No close matches found for '{title}'.\")\n",
    "\n",
    "try:\n",
    "    liked_movie_index = get_index_from_title(anime_liked)\n",
    "    similarity_scores = cdist([features_combined[liked_movie_index]], features_combined, metric='cityblock').flatten()\n",
    "    similar_anime = list(enumerate(similarity_scores))\n",
    "    similar_anime.sort(key=lambda row: row[1])  # Lower Manhattan distance means higher similarity\n",
    "\n",
    "    print(f\"Anime similar to '{anime_liked}' based on Manhattan Distance:\\n\")\n",
    "    for i in range(15):\n",
    "        anime_name = get_title_from_index(similar_anime[i][0])\n",
    "        distance = similar_anime[i][1]\n",
    "        similarity_score = 1 / (1 + distance)  # Convert distance to similarity (closer = higher similarity)\n",
    "        print(f\"{anime_name} - \\t\\tDistance: {distance:.4f}, \\t\\tSimilarity: {similarity_score:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN using Manhattan (with normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.spatial.distance import cdist\n",
    "# from difflib import get_close_matches\n",
    "# import numpy as np\n",
    "\n",
    "# def get_index_from_title(title):\n",
    "#     title = title.strip().lower()\n",
    "#     df[\"Name\"] = df[\"Name\"].str.strip().str.lower()\n",
    "#     matches = get_close_matches(title, df[\"Name\"], n=1, cutoff=0.8)  \n",
    "#     if matches:\n",
    "#         title = matches[0]  \n",
    "#         return df[df[\"Name\"] == title][\"index\"].values[0]\n",
    "#     else:\n",
    "#         raise ValueError(f\"No close matches found for '{title}'.\")\n",
    "\n",
    "# try:\n",
    "#     liked_movie_index = get_index_from_title(anime_liked)\n",
    "    \n",
    "#     # Compute Manhattan (Cityblock) Distance for all anime\n",
    "#     similarity_scores = cdist([features_combined[liked_movie_index]], features_combined, metric='cityblock').flatten()\n",
    "    \n",
    "#     # Find Min & Max for Normalization\n",
    "#     min_distance = np.min(similarity_scores)\n",
    "#     max_distance = np.max(similarity_scores)\n",
    "\n",
    "#     similar_anime = list(enumerate(similarity_scores))\n",
    "#     similar_anime.sort(key=lambda row: row[1])  # Lower Manhattan distance means higher similarity\n",
    "\n",
    "#     print(f\"Anime similar to '{anime_liked}' based on Normalized Manhattan Distance:\\n\")\n",
    "#     for i in range(15):\n",
    "#         anime_name = get_title_from_index(similar_anime[i][0])\n",
    "#         raw_distance = similar_anime[i][1]\n",
    "#         normalized_distance = (raw_distance - min_distance) / (max_distance - min_distance)\n",
    "#         normalized_similarity = 1 - normalized_distance\n",
    "\n",
    "#         print(f\"{anime_name} - \\t\\tDistance: {normalized_distance:.4f}, \\t\\tSimilarity: {normalized_similarity:.4f}\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN using Euclidean (without normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anime similar to 'One-piece' based on Euclidean Distance:\n",
      "\n",
      "one piece - \t\tDistance: 0.0000, \t\tSimilarity: 1.0000\n",
      "dragon ball z - \t\tDistance: 2.1403, \t\tSimilarity: 0.3184\n",
      "hunter x hunter (2011) - \t\tDistance: 2.2018, \t\tSimilarity: 0.3123\n",
      "soul eater - \t\tDistance: 2.3474, \t\tSimilarity: 0.2987\n",
      "my hero academia 2 - \t\tDistance: 2.3614, \t\tSimilarity: 0.2975\n",
      "code geass: lelouch of the rebellion r2 - \t\tDistance: 2.4098, \t\tSimilarity: 0.2933\n",
      "no game no life - \t\tDistance: 2.4127, \t\tSimilarity: 0.2930\n",
      "toradora! - \t\tDistance: 2.5169, \t\tSimilarity: 0.2843\n",
      "blue exorcist - \t\tDistance: 2.5269, \t\tSimilarity: 0.2835\n",
      "ouran high school host club - \t\tDistance: 2.5621, \t\tSimilarity: 0.2807\n",
      "angel beats! - \t\tDistance: 2.5936, \t\tSimilarity: 0.2783\n",
      "fairy tail - \t\tDistance: 2.6467, \t\tSimilarity: 0.2742\n",
      "cowboy bebop - \t\tDistance: 2.6611, \t\tSimilarity: 0.2731\n",
      "highschool of the dead - \t\tDistance: 2.7921, \t\tSimilarity: 0.2637\n",
      "tokyo ghoul - \t\tDistance: 2.8093, \t\tSimilarity: 0.2625\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "try:\n",
    "    liked_movie_index = get_index_from_title(anime_liked)\n",
    "    similarity_scores = cdist([features_combined[liked_movie_index]], features_combined, metric='euclidean').flatten()\n",
    "    # Find Min & Max for Normalization\n",
    "    min_distance = np.min(similarity_scores)\n",
    "    max_distance = np.max(similarity_scores)\n",
    "\n",
    "    similar_anime = list(enumerate(similarity_scores))\n",
    "    similar_anime.sort(key=lambda row: row[1])  # Lower Euclidean distance means higher similarity\n",
    "\n",
    "    print(f\"Anime similar to '{anime_liked}' based on Euclidean Distance:\\n\")\n",
    "    for i in range(15):\n",
    "        anime_name = get_title_from_index(similar_anime[i][0])\n",
    "        distance = similar_anime[i][1]\n",
    "        similarity_score = 1 / (1 + distance)\n",
    "        print(f\"{anime_name} - \\t\\tDistance: {distance:.4f}, \\t\\tSimilarity: {similarity_score:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN using Euclidean (with normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.spatial.distance import cdist\n",
    "\n",
    "# try:\n",
    "#     liked_movie_index = get_index_from_title(anime_liked)\n",
    "#     similarity_scores = cdist([features_combined[liked_movie_index]], features_combined, metric='euclidean').flatten()\n",
    "#     # Find Min & Max for Normalization\n",
    "#     min_distance = np.min(similarity_scores)\n",
    "#     max_distance = np.max(similarity_scores)\n",
    "\n",
    "#     similar_anime = list(enumerate(similarity_scores))\n",
    "#     similar_anime.sort(key=lambda row: row[1])  # Lower Euclidean distance means higher similarity\n",
    "\n",
    "#     print(f\"Anime similar to '{anime_liked}' based on Euclidean Distance:\\n\")\n",
    "#     for i in range(15):\n",
    "#         anime_name = get_title_from_index(similar_anime[i][0])\n",
    "#         raw_distance = similar_anime[i][1]\n",
    "#         normalized_distance = (raw_distance - min_distance) / (max_distance - min_distance)\n",
    "#         normalized_similarity = 1 - normalized_distance\n",
    "#         print(f\"{anime_name} - \\t\\tDistance: {normalized_distance:.4f}, \\t\\tSimilarity: {normalized_similarity:.4f}\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN using Hamming (without normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.spatial.distance import cdist\n",
    "\n",
    "# try:\n",
    "#     liked_movie_index = get_index_from_title(anime_liked)\n",
    "#     similarity_scores = cdist([features_combined[liked_movie_index]], features_combined, metric='hamming').flatten()\n",
    "#     similar_anime = list(enumerate(similarity_scores))\n",
    "#     similar_anime.sort(key=lambda row: row[1])  # Lower Hamming distance means higher similarity\n",
    "\n",
    "#     print(f\"Anime similar to '{anime_liked}' based on Hamming Distance:\\n\")\n",
    "#     for i in range(15):\n",
    "#         anime_name = get_title_from_index(similar_anime[i][0])\n",
    "#         distance = similar_anime[i][1]\n",
    "#         similarity_score = 1 - distance  # Hamming similarity is (1 - distance)\n",
    "#         print(f\"{anime_name} - \\t\\tDistance: {distance:.4f}, \\t\\tSimilarity: {similarity_score:.4f}\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN using Jaccard (without normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.spatial.distance import cdist\n",
    "\n",
    "# try:\n",
    "#     liked_movie_index = get_index_from_title(anime_liked)\n",
    "#     similarity_scores = cdist([features_combined[liked_movie_index]], features_combined, metric='jaccard').flatten()\n",
    "#      # Find Min & Max for Normalization\n",
    "#     min_distance = np.min(similarity_scores)\n",
    "#     max_distance = np.max(similarity_scores)\n",
    "#     similar_anime = list(enumerate(similarity_scores))\n",
    "#     similar_anime.sort(key=lambda row: row[1])  # Lower Jaccard distance means higher similarity\n",
    "\n",
    "#     print(f\"Anime similar to '{anime_liked}' based on Jaccard Distance:\\n\")\n",
    "#     for i in range(15):\n",
    "#         anime_name = get_title_from_index(similar_anime[i][0])\n",
    "#         raw_distance = similar_anime[i][1]\n",
    "#         normalized_distance = (raw_distance - min_distance) / (max_distance - min_distance)\n",
    "#         normalized_similarity = 1 - normalized_distance\n",
    "#         print(f\"{anime_name} - \\t\\tDistance: {distance:.4f}, \\t\\tSimilarity: {similarity_score:.4f}\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Sample Data (replace this with your actual dataset)\n",
    "# # df = pd.DataFrame({\n",
    "# #     'Name': ['Naruto', 'One Piece', 'Attack on Titan', 'Demon Slayer', 'My Hero Academia'],\n",
    "# #     'Tags': ['Drama, Action, Adventure', 'Action, Adventure', 'Action, Drama', 'Action, Supernatural', 'Action, Drama'],\n",
    "# #     'Rating Score': [8.5, 9.0, 8.8, 8.7, 8.9]\n",
    "# # })\n",
    "\n",
    "# # Preprocess the Tags column: Ensure tags are sorted alphabetically\n",
    "# data['Tags'] = data['Tags'].fillna('')\n",
    "# data['Tags'] = data['Tags'].apply(lambda x: ', '.join(sorted(x.split(', '))))  # Sort tags alphabetically\n",
    "\n",
    "# # Function to recommend anime based on genre/tag\n",
    "# def recommend_by_genre(genre, top_n=15):\n",
    "#     # Find anime with the selected tag\n",
    "#     selected_genre_index = [i for i, tags in enumerate(data['Tags']) if genre in tags]\n",
    "\n",
    "#     if not selected_genre_index:\n",
    "#         return f\"No anime found with the tag: {genre}\"\n",
    "\n",
    "#     # Filter the recommended anime based on the selected genre\n",
    "#     recommended_anime = data.iloc[selected_genre_index][['Name', 'Tags', 'Rating Score']]\n",
    "\n",
    "#     # Sort the recommendations by Rating Score in descending order\n",
    "#     recommended_anime = recommended_anime.sort_values(by='Rating Score', ascending=False)\n",
    "\n",
    "#     # Return the top_n recommendations\n",
    "#     return recommended_anime.head(top_n)\n",
    "\n",
    "# # User input for genre/tag\n",
    "# selected_tag = \"Action\"\n",
    "\n",
    "# # Get recommendations based on the selected tag\n",
    "# recommended_anime = recommend_by_genre(selected_tag)\n",
    "\n",
    "# print(\"\\nRecommended anime sorted by rating (Top 15):\")\n",
    "# print(recommended_anime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # Reduce dimensions to 2D\n",
    "# pca = PCA(n_components=2)\n",
    "# features_2D = pca.fit_transform(features_combined)\n",
    "\n",
    "# # Plot the transformed data\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(features_2D[:, 0], features_2D[:, 1], alpha=0.5, c='blue')\n",
    "# plt.xlabel(\"Principal Component 1\")\n",
    "# plt.ylabel(\"Principal Component 2\")\n",
    "# plt.title(\"2D PCA Visualization of Anime Features\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# # Reduce dimensions to 3D\n",
    "# pca_3d = PCA(n_components=3)\n",
    "# features_3D = pca_3d.fit_transform(features_combined)\n",
    "\n",
    "# # 3D scatter plot\n",
    "# fig = plt.figure(figsize=(10, 7))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(features_3D[:, 0], features_3D[:, 1], features_3D[:, 2], alpha=0.5, c='green')\n",
    "\n",
    "# ax.set_xlabel(\"PC1\")\n",
    "# ax.set_ylabel(\"PC2\")\n",
    "# ax.set_zlabel(\"PC3\")\n",
    "# ax.set_title(\"3D PCA Visualization of Anime Features\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# # Reduce dimensions to 2D\n",
    "# tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "# features_2D = tsne.fit_transform(features_combined)\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(features_2D[:, 0], features_2D[:, 1], alpha=0.5, c='blue')\n",
    "# plt.xlabel(\"t-SNE Component 1\")\n",
    "# plt.ylabel(\"t-SNE Component 2\")\n",
    "# plt.title(\"t-SNE 2D Visualization of Anime Features\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# # Fit kNN model\n",
    "# knn = NearestNeighbors(n_neighbors=5, metric=\"euclidean\")\n",
    "# knn.fit(features_2D)\n",
    "\n",
    "# # Get nearest neighbors\n",
    "# distances, indices = knn.kneighbors(features_2D)\n",
    "\n",
    "# # Create a graph\n",
    "# G = nx.Graph()\n",
    "# for i in range(features_2D.shape[0]):\n",
    "#     for j in range(1, 5):  # Connect each point to its 4 nearest neighbors\n",
    "#         G.add_edge(i, indices[i][j], weight=distances[i][j])\n",
    "\n",
    "# # Plot graph\n",
    "# plt.figure(figsize=(12, 8))\n",
    "\n",
    "# # Get positions for graph layout\n",
    "# pos = {i: features_2D[i] for i in range(features_2D.shape[0])}\n",
    "\n",
    "# # Draw nodes (smaller, transparent)\n",
    "# nx.draw_networkx_nodes(G, pos, node_size=15, alpha=0.6)\n",
    "\n",
    "# # Draw edges (lighter, thinner)\n",
    "# nx.draw_networkx_edges(G, pos, edge_color='black', alpha=0.5, width=0.5)\n",
    "\n",
    "# # Highlight a specific anime and its neighbors\n",
    "# anime_index = np.random.randint(0, features_2D.shape[0])  # Choose a random anime\n",
    "# highlight_nodes = [anime_index] + list(indices[anime_index, 1:5])\n",
    "\n",
    "# nx.draw_networkx_nodes(G, pos, nodelist=highlight_nodes, node_color='red', node_size=50)\n",
    "# nx.draw_networkx_edges(G, pos, edgelist=[(anime_index, n) for n in indices[anime_index, 1:5]], edge_color='red', width=1.5)\n",
    "\n",
    "# # Label only a few top-rated animes# Ensure 'Rating Score' is numeric\n",
    "# df['Rating Score'] = pd.to_numeric(df['Rating Score'], errors='coerce')\n",
    "\n",
    "# # Label only a few top-rated animes (after fixing dtype)\n",
    "# for i in df.nlargest(5, 'Rating Score').index:\n",
    "#     plt.text(features_2D[i, 0], features_2D[i, 1], df.loc[i, 'Name'], fontsize=8, ha='right', color='blue')\n",
    "\n",
    "\n",
    "# plt.title(\"Improved K-Nearest Neighbors Graph for Anime\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "# import numpy as np\n",
    "\n",
    "# # Reduce dimensions to 2D using PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# features_2D = pca.fit_transform(features_combined)\n",
    "\n",
    "# # Assign colors based on genres (Tags)\n",
    "# unique_tags = df['Tags'].unique()\n",
    "# color_map = {tag: i for i, tag in enumerate(unique_tags)}  # Assigning unique colors to each tag\n",
    "# colors = [color_map[tag] if tag in color_map else 0 for tag in df['Tags']]  # Map colors to anime\n",
    "\n",
    "# # Scatter plot with color mapping\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(features_2D[:, 0], features_2D[:, 1], c=colors, cmap='jet', alpha=0.7)\n",
    "# plt.colorbar(label=\"Genres (Encoded)\")\n",
    "# plt.xlabel(\"Principal Component 1\")\n",
    "# plt.ylabel(\"Principal Component 2\")\n",
    "# plt.title(\"2D PCA Visualization of Anime Features (Colored by Genre)\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "# import numpy as np\n",
    "\n",
    "# # Reduce dimensions to 2D using PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# features_2D = pca.fit_transform(features_combined)\n",
    "\n",
    "# # Assign colors based on genres (Tags)\n",
    "# unique_tags = df['Tags'].unique()\n",
    "# color_map = {tag: i for i, tag in enumerate(unique_tags)}  # Assigning unique colors to each tag\n",
    "# colors = [color_map[tag] if tag in color_map else 0 for tag in df['Tags']]  # Map colors to anime\n",
    "\n",
    "# # Print encoding values in terminal\n",
    "# print(\"\\n🔹 **Genre Encoding (Tag → Encoded Value)**\")\n",
    "# for tag, value in color_map.items():\n",
    "#     print(f\"{tag}: {value}\")\n",
    "\n",
    "# # Scatter plot with color mapping\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# scatter = plt.scatter(features_2D[:, 0], features_2D[:, 1], c=colors, cmap='jet', alpha=0.7)\n",
    "# plt.colorbar(label=\"Genres (Encoded)\")\n",
    "\n",
    "# # Label first 5 animes as an example\n",
    "# for i in range(5):\n",
    "#     plt.text(features_2D[i, 0], features_2D[i, 1], df.loc[i, 'Name'], fontsize=8, ha='right', color='black')\n",
    "\n",
    "# plt.xlabel(\"Principal Component 1\")\n",
    "# plt.ylabel(\"Principal Component 2\")\n",
    "# plt.title(\"2D PCA Visualization of Anime Features (Colored by Genre)\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # Step 1: Split multi-genre tags\n",
    "# df['Tags'] = df['Tags'].apply(lambda x: x.split(', ') if isinstance(x, str) else [])  # Convert comma-separated tags into lists\n",
    "\n",
    "# # Step 2: Flatten the tag list to create a unique mapping\n",
    "# all_tags = sorted(set(tag for tags in df['Tags'] for tag in tags))  # Get all unique genres\n",
    "# color_map = {tag: i for i, tag in enumerate(all_tags)}  # Assign unique colors\n",
    "\n",
    "# # Step 3: Assign a single genre per anime (choose first genre for simplicity)\n",
    "# df['Primary_Tag'] = df['Tags'].apply(lambda x: x[0] if x else 'Unknown')\n",
    "\n",
    "# # Step 4: Map colors to primary genres\n",
    "# colors = [color_map[tag] if tag in color_map else 0 for tag in df['Primary_Tag']]\n",
    "\n",
    "# # Step 5: Print genre encoding in terminal\n",
    "# print(\"\\n🔹 **Genre Encoding (Tag → Encoded Value)**\")\n",
    "# for tag, value in color_map.items():\n",
    "#     print(f\"{tag}: {value}\")\n",
    "\n",
    "# # Step 6: Perform PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# features_2D = pca.fit_transform(features_combined)\n",
    "\n",
    "# # Step 7: Scatter plot with color mapping\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# scatter = plt.scatter(features_2D[:, 0], features_2D[:, 1], c=colors, cmap='plasma')\n",
    "# plt.colorbar(label=\"Genres (Encoded)\")\n",
    "\n",
    "# # Step 8: Label first 5 animes as an example\n",
    "# for i in range(5):\n",
    "#     plt.text(features_2D[i, 0], features_2D[i, 1], df.loc[i, 'Name'], fontsize=8, ha='right', color='black')\n",
    "\n",
    "# plt.xlabel(\"Principal Component 1\")\n",
    "# plt.ylabel(\"Principal Component 2\")\n",
    "# plt.title(\"2D PCA Visualization of Anime Features (Colored by Genre)\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # Step 1: Split multi-genre tags\n",
    "# df['Tags'] = df['Tags'].apply(lambda x: x.split(', ') if isinstance(x, str) else [])  # Convert comma-separated tags into lists\n",
    "\n",
    "# # Step 2: Flatten the tag list to create a unique mapping\n",
    "# all_tags = sorted(set(tag for tags in df['Tags'] for tag in tags))  # Get all unique genres\n",
    "# color_map = {tag: i for i, tag in enumerate(all_tags)}  # Assign unique colors\n",
    "\n",
    "# # Step 3: Assign a single genre per anime (choose first genre for simplicity)\n",
    "# df['Primary_Tag'] = df['Tags'].apply(lambda x: x[0] if x else 'Unknown')\n",
    "\n",
    "# # Step 4: Map colors to primary genres\n",
    "# colors = [color_map[tag] if tag in color_map else 0 for tag in df['Primary_Tag']]\n",
    "\n",
    "# # Step 5: Print genre encoding in terminal\n",
    "# print(\"\\n🔹 **Genre Encoding (Tag → Encoded Value)**\")\n",
    "# for tag, value in color_map.items():\n",
    "#     print(f\"{tag}: {value}\")\n",
    "\n",
    "# # Step 6: Perform PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# features_2D = pca.fit_transform(features_combined)\n",
    "\n",
    "# # Step 7: Scatter plot with color mapping\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# scatter = plt.scatter(features_2D[:, 0], features_2D[:, 1], c=colors, cmap='plasma', alpha=0.7)\n",
    "# plt.colorbar(label=\"Genres (Encoded)\")\n",
    "\n",
    "# # Step 8: Label top 5 highest-rated anime\n",
    "# top_5_anime = df.nlargest(5, 'Rating Score')\n",
    "# for i in top_5_anime.index:\n",
    "#     plt.text(features_2D[i, 0], features_2D[i, 1], df.loc[i, 'Name'], fontsize=9, ha='right', color='black')\n",
    "\n",
    "# plt.xlabel(\"Principal Component 1\")\n",
    "# plt.ylabel(\"Principal Component 2\")\n",
    "# plt.title(\"2D PCA Visualization of Anime Features (Top 5 Anime Highlighted)\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # Step 1: Split multi-genre tags\n",
    "# df['Tags'] = df['Tags'].apply(lambda x: x.split(', ') if isinstance(x, str) else [])  # Convert comma-separated tags into lists\n",
    "\n",
    "# # Step 2: Flatten the tag list to create a unique mapping\n",
    "# all_tags = sorted(set(tag for tags in df['Tags'] for tag in tags))  # Get all unique genres\n",
    "# color_map = {tag: i for i, tag in enumerate(all_tags)}  # Assign unique colors\n",
    "\n",
    "# # Step 3: Assign a single genre per anime (choose first genre for simplicity)\n",
    "# df['Primary_Tag'] = df['Tags'].apply(lambda x: x[0] if x else 'Unknown')\n",
    "\n",
    "# # Step 4: Map colors to primary genres\n",
    "# colors = [color_map[tag] if tag in color_map else 0 for tag in df['Primary_Tag']]\n",
    "\n",
    "# # Step 5: Print genre encoding in terminal\n",
    "# print(\"\\n🔹 **Genre Encoding (Tag → Encoded Value)**\")\n",
    "# for tag, value in color_map.items():\n",
    "#     print(f\"{tag}: {value}\")\n",
    "\n",
    "# # Step 6: Perform PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# features_2D = pca.fit_transform(features_combined)\n",
    "\n",
    "# # Extract PC1 and PC2\n",
    "# PC1 = features_2D[:, 0]  # First principal component\n",
    "# PC2 = features_2D[:, 1]  # Second principal component\n",
    "\n",
    "# # Print PC1 and PC2 values in terminal\n",
    "# print(\"\\n🔹 **Principal Component 1 (PC1) Values:**\")\n",
    "# print(PC1)\n",
    "\n",
    "# print(\"\\n🔹 **Principal Component 2 (PC2) Values:**\")\n",
    "# print(PC2)\n",
    "\n",
    "# # Step 7: Scatter plot with color mapping\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# scatter = plt.scatter(PC1, PC2, c=colors, cmap='plasma', alpha=0.7)\n",
    "# plt.colorbar(label=\"Genres (Encoded)\")\n",
    "\n",
    "# # Step 8: Label top 5 highest-rated anime\n",
    "# top_5_anime = df.nlargest(5, 'Rating Score')\n",
    "# for i in top_5_anime.index:\n",
    "#     plt.text(PC1[i], PC2[i], df.loc[i, 'Name'], fontsize=9, ha='right', color='black')\n",
    "\n",
    "# plt.xlabel(\"Principal Component 1\")\n",
    "# plt.ylabel(\"Principal Component 2\")\n",
    "# plt.title(\"2D PCA Visualization of Anime Features (Top 5 Anime Highlighted)\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # Perform PCA to reduce dimensions to 2D\n",
    "# pca = PCA(n_components=2)\n",
    "# features_2D = pca.fit_transform(features_combined)\n",
    "\n",
    "# # Extract Principal Components\n",
    "# PC1 = features_2D[:, 0]  # First Principal Component\n",
    "# PC2 = features_2D[:, 1]  # Second Principal Component\n",
    "\n",
    "# # Get anime names\n",
    "# anime_names = df[\"Name\"].values\n",
    "\n",
    "# # Plot Anime Name vs. PC1\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.barh(anime_names[:30], PC1[:30], color='skyblue')  # Plot first 30 anime for clarity\n",
    "# plt.xlabel(\"Principal Component 1 (PC1)\")\n",
    "# plt.ylabel(\"Anime Name\")\n",
    "# plt.title(\"Anime vs. Feature Representation (PC1)\")\n",
    "# plt.gca().invert_yaxis()  # Invert for readability\n",
    "# plt.show()\n",
    "\n",
    "# # Scatter Plot of PC1 vs. PC2\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(PC1, PC2, alpha=0.7, c='blue')\n",
    "# plt.xlabel(\"Principal Component 1\")\n",
    "# plt.ylabel(\"Principal Component 2\")\n",
    "# plt.title(\"2D PCA Visualization of Anime Features\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# # Reduce dimensions to 2D using t-SNE\n",
    "# tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "# features_2D = tsne.fit_transform(features_combined)\n",
    "\n",
    "# # Scatter plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(features_2D[:, 0], features_2D[:, 1], alpha=0.7, c='blue')\n",
    "# plt.xlabel(\"t-SNE Component 1\")\n",
    "# plt.ylabel(\"t-SNE Component 2\")\n",
    "# plt.title(\"2D t-SNE Visualization of Anime Features\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Reduce dimensions to 2D using PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# features_2D = pca.fit_transform(features_combined)\n",
    "\n",
    "# # Define important animes (Top 10 by rating)\n",
    "# top_anime = df.nlargest(10, 'Rating Score')\n",
    "\n",
    "# # Scatter plot\n",
    "# plt.figure(figsize=(12, 7))\n",
    "# plt.scatter(features_2D[:, 0], features_2D[:, 1], alpha=0.7, c='blue')\n",
    "\n",
    "# # Label top animes\n",
    "# for i, row in top_anime.iterrows():\n",
    "#     plt.text(features_2D[i, 0], features_2D[i, 1], row['Name'], fontsize=9, ha='right')\n",
    "\n",
    "# plt.xlabel(\"Principal Component 1\")\n",
    "# plt.ylabel(\"Principal Component 2\")\n",
    "# plt.title(\"2D PCA Visualization of Anime Features (Top Animes Labeled)\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# # Load the dataset\n",
    "# df = pd.read_csv(\"..\\\\anime.csv\")\n",
    "\n",
    "# # Fill NaN values\n",
    "# df['Tags'] = df['Tags'].fillna('')\n",
    "\n",
    "# # TF-IDF Vectorization for Tags\n",
    "# tag_vectorizer = TfidfVectorizer(stop_words='english', max_features=600)\n",
    "# tag_matrix = tag_vectorizer.fit_transform(df['Tags']).toarray()\n",
    "\n",
    "# # PCA to reduce features to 2D space\n",
    "# pca = PCA(n_components=2)\n",
    "# pca_features = pca.fit_transform(tag_matrix)\n",
    "\n",
    "# # Convert PCA output to DataFrame\n",
    "# df_pca = pd.DataFrame(pca_features, columns=['PC1', 'PC2'])\n",
    "# df_pca['Anime Name'] = df['Name']\n",
    "# df_pca['Genre'] = df['Tags'].apply(lambda x: x.split(',')[0])  # Take the first genre tag\n",
    "\n",
    "# # Plot the clusters\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.scatterplot(data=df_pca, x='PC1', y='PC2', hue='Genre', palette='tab10', alpha=0.7)\n",
    "# plt.title(\"Anime Clusters by Genre (PCA)\")\n",
    "# plt.xlabel(\"Principal Component 1 (PC1)\")\n",
    "# plt.ylabel(\"Principal Component 2 (PC2)\")\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# # Define KNN model\n",
    "# knn = NearestNeighbors(n_neighbors=12, metric='cosine')  # 6 includes Naruto itself\n",
    "# knn.fit(tag_matrix)\n",
    "\n",
    "# # Find Naruto's index\n",
    "# anime1 = df[df[\"Name\"].str.contains(\"Naruto\", case=False, na=False)].index[0]\n",
    "\n",
    "# # Get Naruto's nearest neighbors\n",
    "# distances, indices = knn.kneighbors(tag_matrix[anime1].reshape(1, -1))\n",
    "\n",
    "# # Print the top 5 most similar anime\n",
    "# print(\"Top 5 Anime Similar to Naruto:\")\n",
    "# for i in indices[0][1:]:\n",
    "#     print(df.iloc[i]['Name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.metrics.pairwise import cosine_distances\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Apply PCA to reduce tag features to 2D\n",
    "# pca = PCA(n_components=2)\n",
    "# pca_features = pca.fit_transform(tag_matrix)\n",
    "\n",
    "# # Get indices of Naruto and Your Lie in April\n",
    "# anime1 = df[df[\"Name\"].str.contains(\"Naruto\", case=False, na=False)].index[0]\n",
    "# ylia_index = df[df[\"Name\"].str.contains(\"Your Lie in April\", case=False, na=False)].index[0]\n",
    "\n",
    "# # Compute distance using cosine similarity\n",
    "# distance = cosine_distances([tag_matrix[anime1]], [tag_matrix[ylia_index]])[0][0]\n",
    "\n",
    "# # Plot their placement on PCA space\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.scatter(pca_features[:, 0], pca_features[:, 1], alpha=0.5, label=\"Other Anime\", color=\"gray\")\n",
    "# plt.scatter(pca_features[anime1, 0], pca_features[anime1, 1], color='red', label=\"Naruto\", s=100)\n",
    "# plt.scatter(pca_features[ylia_index, 0], pca_features[ylia_index, 1], color='blue', label=\"Your Lie in April\", s=100)\n",
    "\n",
    "# # Draw line between them\n",
    "# plt.plot([pca_features[anime1, 0], pca_features[ylia_index, 0]], \n",
    "#          [pca_features[anime1, 1], pca_features[ylia_index, 1]], \n",
    "#          color='black', linestyle=\"dashed\", linewidth=1.5)\n",
    "\n",
    "# # Labels & title\n",
    "# plt.title(f\"Distance Between Naruto and Your Lie in April: {distance:.3f}\")\n",
    "# plt.xlabel(\"Principal Component 1 (PC1)\")\n",
    "# plt.ylabel(\"Principal Component 2 (PC2)\")\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.metrics.pairwise import cosine_distances\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Apply PCA to reduce tag features to 2D\n",
    "# pca = PCA(n_components=2)\n",
    "# pca_features = pca.fit_transform(tag_matrix)\n",
    "\n",
    "# # Get indices of Naruto and Your Lie in April\n",
    "# anime1 = df[df[\"Name\"].str.contains(\"Naruto\", case=False, na=False)].index[0]\n",
    "# ylia_index = df[df[\"Name\"].str.contains(\"bleach\", case=False, na=False)].index[0]\n",
    "\n",
    "# # Compute distance using cosine similarity\n",
    "# distance = cosine_distances([tag_matrix[anime1]], [tag_matrix[ylia_index]])[0][0]\n",
    "\n",
    "# # Plot their placement on PCA space\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.scatter(pca_features[:, 0], pca_features[:, 1], alpha=0.5, label=\"Other Anime\", color=\"gray\")\n",
    "# plt.scatter(pca_features[anime1, 0], pca_features[anime1, 1], color='red', label=\"Naruto\", s=100)\n",
    "# plt.scatter(pca_features[ylia_index, 0], pca_features[ylia_index, 1], color='blue', label=\"Your Lie in April\", s=100)\n",
    "\n",
    "# # Draw line between them\n",
    "# plt.plot([pca_features[anime1, 0], pca_features[ylia_index, 0]], \n",
    "#          [pca_features[anime1, 1], pca_features[ylia_index, 1]], \n",
    "#          color='black', linestyle=\"dashed\", linewidth=1.5)\n",
    "\n",
    "# # Labels & title\n",
    "# plt.title(f\"Distance Between Naruto and Your Lie in April: {distance:.3f}\")\n",
    "# plt.xlabel(\"Principal Component 1 (PC1)\")\n",
    "# plt.ylabel(\"Principal Component 2 (PC2)\")\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.metrics.pairwise import cosine_distances\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# # ✅ Sort anime by Rating Score (descending order)\n",
    "# top_10_anime = df.sort_values(by=\"Rating Score\", ascending=False).head(10)\n",
    "\n",
    "# # ✅ Apply PCA to reduce tag features to 2D\n",
    "# pca = PCA(n_components=2)\n",
    "# pca_features = pca.fit_transform(tag_matrix)\n",
    "\n",
    "# # ✅ Get index of Naruto\n",
    "# anime1 = df[df[\"Name\"].str.contains(\"Naruto\", case=False, na=False)].index[0]\n",
    "\n",
    "# # ✅ Compute distances between Naruto and each of the top 10 anime\n",
    "# distances = {}\n",
    "# for anime_name in top_10_anime[\"Name\"]:\n",
    "#     anime_index = df[df[\"Name\"] == anime_name].index[0]\n",
    "#     dist = cosine_distances([tag_matrix[anime1]], [tag_matrix[anime_index]])[0][0]\n",
    "#     distances[anime_name] = dist\n",
    "\n",
    "# # ✅ Print distances\n",
    "# print(\"\\n🔹 Cosine Distances from Naruto to Bottom 10 Anime:\")\n",
    "# for anime, dist in distances.items():\n",
    "#     print(f\"{anime}: {dist:.3f}\")\n",
    "\n",
    "# # ✅ Plot Naruto and the top 10 anime\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(pca_features[:, 0], pca_features[:, 1], alpha=0.3, label=\"Other Anime\", color=\"gray\")\n",
    "\n",
    "# # ✅ Highlight Naruto\n",
    "# plt.scatter(pca_features[anime1, 0], pca_features[anime1, 1], color='red', label=\"Naruto\", s=100)\n",
    "\n",
    "# # ✅ Highlight top 10 anime\n",
    "# for anime_name in top_10_anime[\"Name\"]:\n",
    "#     anime_index = df[df[\"Name\"] == anime_name].index[0]\n",
    "#     plt.scatter(pca_features[anime_index, 0], pca_features[anime_index, 1], label=anime_name, s=80)\n",
    "\n",
    "#     # ✅ Draw dashed line from Naruto to each top anime\n",
    "#     plt.plot([pca_features[anime1, 0], pca_features[anime_index, 0]], \n",
    "#              [pca_features[anime1, 1], pca_features[anime_index, 1]], \n",
    "#              color='black', linestyle=\"dashed\", linewidth=1)\n",
    "\n",
    "# # ✅ Labels & title\n",
    "# plt.title(\"Cosine Distance Between Naruto and Top 10 Anime\")\n",
    "# plt.xlabel(\"Principal Component 1 (PC1)\")\n",
    "# plt.ylabel(\"Principal Component 2 (PC2)\")\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.metrics.pairwise import cosine_distances\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# # ✅ Define the top 10 anime manually\n",
    "# top_10_anime_names = [\n",
    "#     \"Fullmetal Alchemist: Brotherhood\",\n",
    "#     \"Attack on Titan The Final Season\",\n",
    "#     \"Demon Slayer: Kimetsu no Yaiba Movie - Mugen Train\",\n",
    "#     \"Attack on Titan 3rd Season: Part II\",\n",
    "#     \"Jujutsu Kaisen\",\n",
    "#     \"Hunter x Hunter (2011)\",\n",
    "#     \"Demon Slayer: Kimetsu no Yaiba\",\n",
    "#     \"Gintama Kanketsu-hen: Yorozuya yo Eien Nare\",\n",
    "#     \"Gintama (2015)\",\n",
    "#     \"Mob Psycho 100 II\"\n",
    "# ]\n",
    "\n",
    "# # ✅ Filter dataset for these anime\n",
    "# top_10_anime = df[df[\"Name\"].isin(top_10_anime_names)]\n",
    "\n",
    "# # ✅ Apply PCA to reduce tag features to 2D\n",
    "# pca = PCA(n_components=2)\n",
    "# pca_features = pca.fit_transform(tag_matrix)\n",
    "\n",
    "# # ✅ Get Naruto's index\n",
    "# anime1 = df[df[\"Name\"].str.contains(\"Naruto\", case=False, na=False)].index[0]\n",
    "\n",
    "# # ✅ Compute cosine distances from Naruto to each top 10 anime\n",
    "# distances = {}\n",
    "# for anime_name in top_10_anime[\"Name\"]:\n",
    "#     anime_index = df[df[\"Name\"] == anime_name].index[0]\n",
    "#     dist = cosine_distances([tag_matrix[anime1]], [tag_matrix[anime_index]])[0][0]\n",
    "#     distances[anime_name] = dist\n",
    "\n",
    "# # ✅ Print sorted distances\n",
    "# print(\"\\n🔹 Cosine Distances from Naruto to Top 10 Anime:\")\n",
    "# for anime, dist in sorted(distances.items(), key=lambda x: x[1]):\n",
    "#     print(f\"{anime}: {dist:.3f}\")\n",
    "\n",
    "# # ✅ Plot Naruto and the top 10 anime in PCA space\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(pca_features[:, 0], pca_features[:, 1], alpha=0.2, label=\"Other Anime\", color=\"gray\")\n",
    "\n",
    "# # ✅ Highlight Naruto\n",
    "# plt.scatter(pca_features[anime1, 0], pca_features[anime1, 1], color='red', label=\"Naruto\", s=100)\n",
    "\n",
    "# # ✅ Highlight each of the top 10 anime\n",
    "# for anime_name in top_10_anime[\"Name\"]:\n",
    "#     anime_index = df[df[\"Name\"] == anime_name].index[0]\n",
    "#     plt.scatter(pca_features[anime_index, 0], pca_features[anime_index, 1], label=anime_name, s=80)\n",
    "\n",
    "#     # ✅ Draw dashed lines from Naruto to each anime\n",
    "#     plt.plot([pca_features[anime1, 0], pca_features[anime_index, 0]], \n",
    "#              [pca_features[anime1, 1], pca_features[anime_index, 1]], \n",
    "#              color='black', linestyle=\"dashed\", linewidth=1)\n",
    "\n",
    "# # ✅ Labels & title\n",
    "# plt.title(\"Cosine Distance Between Naruto and Top 10 Anime\")\n",
    "# plt.xlabel(\"Principal Component 1 (PC1)\")\n",
    "# plt.ylabel(\"Principal Component 2 (PC2)\")\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.metrics.pairwise import cosine_distances\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# # ✅ Define the top 10 anime manually\n",
    "# top_10_anime_names = [\n",
    "#     \"Fullmetal Alchemist: Brotherhood\",\n",
    "#     \"Attack on Titan The Final Season\",\n",
    "#     \"Demon Slayer: Kimetsu no Yaiba Movie - Mugen Train\",\n",
    "#     \"Attack on Titan 3rd Season: Part II\",\n",
    "#     \"Jujutsu Kaisen\",\n",
    "#     \"Hunter x Hunter (2011)\",\n",
    "#     \"Demon Slayer: Kimetsu no Yaiba\",\n",
    "#     \"Gintama Kanketsu-hen: Yorozuya yo Eien Nare\",\n",
    "#     \"Gintama (2015)\",\n",
    "#     \"Mob Psycho 100 II\"\n",
    "# ]\n",
    "\n",
    "# # ✅ Filter dataset for these anime\n",
    "# top_10_anime = df[df[\"Name\"].isin(top_10_anime_names)]\n",
    "\n",
    "# # ✅ Apply PCA to reduce tag features to 2D\n",
    "# pca = PCA(n_components=2)\n",
    "# pca_features = pca.fit_transform(tag_matrix)\n",
    "\n",
    "# # ✅ Get Naruto's index\n",
    "# anime1 = df[df[\"Name\"].str.contains(\"Naruto\", case=False, na=False)].index[0]\n",
    "\n",
    "# # ✅ Compute cosine distances from Naruto to each top 10 anime\n",
    "# distances = {}\n",
    "# for anime_name in top_10_anime[\"Name\"]:\n",
    "#     anime_index = df[df[\"Name\"] == anime_name].index[0]\n",
    "#     dist = cosine_distances([tag_matrix[anime1]], [tag_matrix[anime_index]])[0][0]\n",
    "#     distances[anime_name] = dist\n",
    "\n",
    "# # ✅ Print sorted distances\n",
    "# print(\"\\n🔹 Cosine Distances from Naruto to Top 10 Anime:\")\n",
    "# for anime, dist in sorted(distances.items(), key=lambda x: x[1]):\n",
    "#     print(f\"{anime}: {dist:.3f}\")\n",
    "\n",
    "# # ✅ Plot Naruto and the top 10 anime in PCA space\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(pca_features[:, 0], pca_features[:, 1], alpha=0.2, label=\"Other Anime\", color=\"gray\")\n",
    "\n",
    "# # ✅ Highlight Naruto\n",
    "# plt.scatter(pca_features[anime1, 0], pca_features[anime1, 1], color='yellow', label=\"Naruto\", s=100)\n",
    "\n",
    "# # ✅ Highlight each of the top 10 anime\n",
    "# for anime_name in top_10_anime[\"Name\"]:\n",
    "#     anime_index = df[df[\"Name\"] == anime_name].index[0]\n",
    "#     plt.scatter(pca_features[anime_index, 0], pca_features[anime_index, 1], label=anime_name, s=80)\n",
    "\n",
    "#     # ✅ Draw dashed lines from Naruto to each anime\n",
    "#     plt.plot([pca_features[anime1, 0], pca_features[anime_index, 0]], \n",
    "#              [pca_features[anime1, 1], pca_features[anime_index, 1]], \n",
    "#              color='black', linestyle=\"dashed\", linewidth=0)\n",
    "\n",
    "# # ✅ Labels & title\n",
    "# plt.title(\"Cosine Distance Between Naruto and Top 10 Anime\")\n",
    "# plt.xlabel(\"Principal Component 1 (PC1)\")\n",
    "# plt.ylabel(\"Principal Component 2 (PC2)\")\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.metrics.pairwise import cosine_distances\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # ✅ Define the top 10 anime manually\n",
    "# top_10_anime_names = [\n",
    "#     \"Fullmetal Alchemist: Brotherhood\",\n",
    "#     \"Attack on Titan The Final Season\",\n",
    "#     \"Demon Slayer: Kimetsu no Yaiba Movie - Mugen Train\",\n",
    "#     \"Attack on Titan 3rd Season: Part II\",\n",
    "#     \"Jujutsu Kaisen\",\n",
    "#     \"Hunter x Hunter (2011)\",\n",
    "#     \"Demon Slayer: Kimetsu no Yaiba\",\n",
    "#     \"Gintama Kanketsu-hen: Yorozuya yo Eien Nare\",\n",
    "#     \"Gintama (2015)\",\n",
    "#     \"Mob Psycho 100 II\"\n",
    "# ]\n",
    "\n",
    "# # ✅ Filter dataset for these anime\n",
    "# top_10_anime = df[df[\"Name\"].isin(top_10_anime_names)]\n",
    "\n",
    "# # ✅ Apply PCA to reduce tag features to 2D\n",
    "# pca = PCA(n_components=2)\n",
    "# pca_features = pca.fit_transform(tag_matrix)\n",
    "\n",
    "# # ✅ Get Naruto's index\n",
    "# anime1 = df[df[\"Name\"].str.contains(\"Naruto\", case=False, na=False)].index[0]\n",
    "\n",
    "# # ✅ Compute cosine distances from Naruto to each top 10 anime\n",
    "# distances = {}\n",
    "# for anime_name in top_10_anime[\"Name\"]:\n",
    "#     anime_index = df[df[\"Name\"] == anime_name].index[0]\n",
    "#     dist = cosine_distances([tag_matrix[anime1]], [tag_matrix[anime_index]])[0][0]\n",
    "#     distances[anime_name] = dist\n",
    "\n",
    "# # ✅ Print sorted distances\n",
    "# print(\"\\n🔹 Cosine Distances from Naruto to Top 10 Anime:\")\n",
    "# for anime, dist in sorted(distances.items(), key=lambda x: x[1]):\n",
    "#     print(f\"{anime}: {dist:.3f}\")\n",
    "\n",
    "# # ✅ Assign colors using a colormap (choose 'plasma' or 'viridis')\n",
    "# cmap = plt.get_cmap(\"viridis\")  # Change to \"viridis\" for a different theme\n",
    "# colors = cmap(np.linspace(0, 1, len(top_10_anime)))\n",
    "\n",
    "# # ✅ Plot Naruto and the top 10 anime in PCA space\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(pca_features[:, 0], pca_features[:, 1], alpha=0.2, label=\"Other Anime\", color=\"gray\")\n",
    "\n",
    "# # ✅ Highlight Naruto in yellow\n",
    "# plt.scatter(pca_features[anime1, 0], pca_features[anime1, 1], color='red', label=\"Naruto\", s=120)\n",
    "# # plt.scatter(pca_features[anime1, 0], pca_features[anime1, 1], color='red', label=\"Naruto\", s=120, edgecolors=\"black\")\n",
    "\n",
    "# # ✅ Highlight each of the top 10 anime with the color gradient\n",
    "# for i, (anime_name, color) in enumerate(zip(top_10_anime[\"Name\"], colors)):\n",
    "#     anime_index = df[df[\"Name\"] == anime_name].index[0]\n",
    "#     plt.scatter(pca_features[anime_index, 0], pca_features[anime_index, 1], label=anime_name, s=100, color=color)   # plt.scatter(pca_features[anime_index, 0], pca_features[anime_index, 1], label=anime_name, s=100, color=color, edgecolors=\"black\")\n",
    "\n",
    "#     # ✅ Draw dashed lines from Naruto to each anime\n",
    "#     plt.plot([pca_features[anime1, 0], pca_features[anime_index, 0]], \n",
    "#              [pca_features[anime1, 1], pca_features[anime_index, 1]], \n",
    "#              color='black', linestyle=\"dashed\", linewidth=0)\n",
    "\n",
    "# # ✅ Labels & title\n",
    "# plt.title(\"Cosine Distance Between Naruto and Top 10 Anime\")\n",
    "# plt.xlabel(\"Principal Component 1 (PC1)\")\n",
    "# plt.ylabel(\"Principal Component 2 (PC2)\")\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.metrics.pairwise import cosine_distances\n",
    "# from scipy.spatial.distance import euclidean, cityblock, hamming, jaccard\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "# # ✅ Define the top 10 anime manually\n",
    "# top_10_anime_names = [\n",
    "#     \"Fullmetal Alchemist: Brotherhood\",\n",
    "#     \"Attack on Titan The Final Season\",\n",
    "#     \"Demon Slayer: Kimetsu no Yaiba Movie - Mugen Train\",\n",
    "#     \"Attack on Titan 3rd Season: Part II\",\n",
    "#     \"Jujutsu Kaisen\",\n",
    "#     \"Hunter x Hunter (2011)\",\n",
    "#     \"Demon Slayer: Kimetsu no Yaiba\",\n",
    "#     \"Gintama Kanketsu-hen: Yorozuya yo Eien Nare\",\n",
    "#     \"Gintama (2015)\",\n",
    "#     \"Mob Psycho 100 II\"\n",
    "# ]\n",
    "\n",
    "# # ✅ Filter dataset for these anime\n",
    "# top_10_anime = df[df[\"Name\"].isin(top_10_anime_names)]\n",
    "\n",
    "# # ✅ Get Naruto's index and feature vector\n",
    "# anime1 = df[df[\"Name\"].str.contains(\"Naruto\", case=False, na=False)].index[0]\n",
    "# naruto_vector = tag_matrix[anime1]\n",
    "\n",
    "# # ✅ Store distances\n",
    "# distances = []\n",
    "\n",
    "# for anime_name in top_10_anime[\"Name\"]:\n",
    "#     anime_index = df[df[\"Name\"] == anime_name].index[0]\n",
    "#     anime_vector = tag_matrix[anime_index]\n",
    "\n",
    "#     # ✅ Compute different distances\n",
    "#     euclidean_dist = euclidean(naruto_vector, anime_vector)\n",
    "#     manhattan_dist = cityblock(naruto_vector, anime_vector)\n",
    "#     hamming_dist = hamming(naruto_vector, anime_vector)\n",
    "#     jaccard_dist = jaccard(naruto_vector, anime_vector)\n",
    "#     cosine_dist = cosine_distances([naruto_vector], [anime_vector])[0][0]\n",
    "\n",
    "#     # ✅ Store results\n",
    "#     distances.append([anime_name, euclidean_dist, manhattan_dist, hamming_dist, jaccard_dist, cosine_dist])\n",
    "\n",
    "# # ✅ Print distances in a table format\n",
    "# print(\"\\n🔹 Distances Between Naruto and Top 10 Anime:\\n\")\n",
    "# print(f\"{'Anime Name':<50} {'Euclidean':<12} {'Manhattan':<12} {'Hamming':<12} {'Jaccard':<12} {'Cosine':<12}\")\n",
    "# print(\"=\" * 90)\n",
    "# for row in distances:\n",
    "#     print(f\"{row[0]:<50} {row[1]:<12.3f} {row[2]:<12.3f} {row[3]:<12.3f} {row[4]:<12.3f} {row[5]:<12.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import umap\n",
    "\n",
    "# # Reduce dimensions to 2D\n",
    "# reducer = umap.UMAP(n_neighbors=10, min_dist=0.3, metric='euclidean')\n",
    "# features_2D_umap = reducer.fit_transform(features_combined)\n",
    "\n",
    "# # Plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(features_2D_umap[:, 0], features_2D_umap[:, 1], alpha=0.5, c='red')\n",
    "# plt.xlabel(\"UMAP Component 1\")\n",
    "# plt.ylabel(\"UMAP Component 2\")\n",
    "# plt.title(\"UMAP 2D Visualization of Anime Features\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anime similar to 'One-piece' based on Chebyshev Distance:\n",
      "\n",
      "one piece - \t\tDistance: 0.0000, \t\tSimilarity: 1.0000\n",
      "ouran high school host club - \t\tDistance: 1.0000, \t\tSimilarity: 0.5000\n",
      "howl's moving castle - \t\tDistance: 1.0000, \t\tSimilarity: 0.5000\n",
      "code geass: lelouch of the rebellion r2 - \t\tDistance: 1.0000, \t\tSimilarity: 0.5000\n",
      "soul eater - \t\tDistance: 1.0000, \t\tSimilarity: 0.5000\n",
      "toradora! - \t\tDistance: 1.0000, \t\tSimilarity: 0.5000\n",
      "princess mononoke - \t\tDistance: 1.0000, \t\tSimilarity: 0.5000\n",
      "angel beats! - \t\tDistance: 1.0000, \t\tSimilarity: 0.5000\n",
      "blue exorcist - \t\tDistance: 1.0000, \t\tSimilarity: 0.5000\n",
      "hunter x hunter (2011) - \t\tDistance: 1.0000, \t\tSimilarity: 0.5000\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from difflib import get_close_matches\n",
    "\n",
    "def get_index_from_title(title):\n",
    "    title = title.strip().lower()\n",
    "    df[\"Name\"] = df[\"Name\"].str.strip().str.lower()\n",
    "    matches = get_close_matches(title, df[\"Name\"], n=1, cutoff=0.8)  \n",
    "    if matches:\n",
    "        title = matches[0]  \n",
    "        return df[df[\"Name\"] == title][\"index\"].values[0]\n",
    "    else:\n",
    "        raise ValueError(f\"No close matches found for '{title}'.\")\n",
    "\n",
    "# Code for Cityblock (Manhattan) Distance\n",
    "def find_similar_anime_cityblock(anime_liked):\n",
    "    try:\n",
    "        liked_movie_index = get_index_from_title(anime_liked)\n",
    "        similarity_scores = cdist([features_combined[liked_movie_index]], features_combined, metric='cityblock').flatten()\n",
    "        similar_anime = list(enumerate(similarity_scores))\n",
    "        similar_anime.sort(key=lambda row: row[1])  # Lower distance means higher similarity\n",
    "\n",
    "        print(f\"Anime similar to '{anime_liked}' based on Cityblock Distance:\\n\")\n",
    "        for i in range(15):\n",
    "            anime_name = get_title_from_index(similar_anime[i][0])\n",
    "            distance = similar_anime[i][1]\n",
    "            similarity_score = 1 / (1 + distance)  # Convert distance to similarity (closer = higher similarity)\n",
    "            print(f\"{anime_name} - \\t\\tDistance: {distance:.4f}, \\t\\tSimilarity: {similarity_score:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Code for Chebyshev Distance\n",
    "def find_similar_anime_chebyshev(anime_liked):\n",
    "    try:\n",
    "        liked_movie_index = get_index_from_title(anime_liked)\n",
    "        similarity_scores = cdist([features_combined[liked_movie_index]], features_combined, metric='chebyshev').flatten()\n",
    "        similar_anime = list(enumerate(similarity_scores))\n",
    "        similar_anime.sort(key=lambda row: row[1])  # Lower distance means higher similarity\n",
    "\n",
    "        print(f\"Anime similar to '{anime_liked}' based on Chebyshev Distance:\\n\")\n",
    "        for i in range(10):\n",
    "            anime_name = get_title_from_index(similar_anime[i][0])\n",
    "            distance = similar_anime[i][1]\n",
    "            similarity_score = 1 / (1 + distance)  # Convert distance to similarity (closer = higher similarity)\n",
    "            print(f\"{anime_name} - \\t\\tDistance: {distance:.4f}, \\t\\tSimilarity: {similarity_score:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "# anime_liked = \"Your Favorite Anime Title Here\"\n",
    "# find_similar_anime_cityblock(anime_liked)\n",
    "find_similar_anime_chebyshev(anime_liked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anime similar to 'One-piece' based on Correlation Distance:\n",
      "\n",
      "one piece - Distance: 0.0000, Similarity: 1.0000\n",
      "dragon ball z - Distance: 0.0138, Similarity: 0.9862\n",
      "death note - Distance: 0.0144, Similarity: 0.9856\n",
      "attack on titan - Distance: 0.0146, Similarity: 0.9854\n",
      "naruto - Distance: 0.0148, Similarity: 0.9852\n",
      "fullmetal alchemist: brotherhood - Distance: 0.0156, Similarity: 0.9844\n",
      "bleach - Distance: 0.0160, Similarity: 0.9840\n",
      "sword art online - Distance: 0.0160, Similarity: 0.9840\n",
      "fullmetal alchemist - Distance: 0.0161, Similarity: 0.9839\n",
      "naruto shippuden - Distance: 0.0163, Similarity: 0.9837\n",
      "my hero academia - Distance: 0.0173, Similarity: 0.9827\n",
      "one-punch man - Distance: 0.0174, Similarity: 0.9826\n",
      "fairy tail - Distance: 0.0178, Similarity: 0.9822\n",
      "hunter x hunter (2011) - Distance: 0.0182, Similarity: 0.9818\n",
      "code geass: lelouch of the rebellion - Distance: 0.0183, Similarity: 0.9817\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def find_similar_anime_correlation(anime_liked):\n",
    "    try:\n",
    "        liked_movie_index = get_index_from_title(anime_liked)\n",
    "        similarity_scores = cdist([features_combined[liked_movie_index]], features_combined, metric='correlation').flatten()\n",
    "        similar_anime = sorted(enumerate(similarity_scores), key=lambda x: x[1])\n",
    "\n",
    "        print(f\"Anime similar to '{anime_liked}' based on Correlation Distance:\\n\")\n",
    "        for i in range(15):\n",
    "            anime_name = get_title_from_index(similar_anime[i][0])\n",
    "            distance = similar_anime[i][1]\n",
    "            similarity_score = 1 - distance  # Closer correlation distance = higher similarity\n",
    "            print(f\"{anime_name} - Distance: {distance:.4f}, Similarity: {similarity_score:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "find_similar_anime_correlation(anime_liked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import spearmanr\n",
    "\n",
    "# def find_similar_anime_spearman(anime_liked):\n",
    "#     try:\n",
    "#         liked_movie_index = get_index_from_title(anime_liked)\n",
    "#         liked_movie_features = features_combined[liked_movie_index]\n",
    "#         similarity_scores = [spearmanr(liked_movie_features, features_combined[i])[0] for i in range(len(features_combined))]\n",
    "#         similar_anime = sorted(enumerate(similarity_scores), key=lambda x: -x[1])  # Higher Spearman rank means more similarity\n",
    "\n",
    "#         print(f\"Anime similar to '{anime_liked}' based on Spearman Correlation:\\n\")\n",
    "#         for i in range(15):\n",
    "#             anime_name = get_title_from_index(similar_anime[i][0])\n",
    "#             correlation = similar_anime[i][1]\n",
    "#             print(f\"{anime_name} - Correlation: {correlation:.4f}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error: {e}\")\n",
    "\n",
    "# find_similar_anime_spearman(anime_liked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import spearmanr\n",
    "\n",
    "# def find_similar_anime_spearman(anime_liked):\n",
    "#     try:\n",
    "#         liked_movie_index = get_index_from_title(anime_liked)\n",
    "#         liked_movie_features = features_combined[liked_movie_index]\n",
    "\n",
    "#         similarity_scores = []\n",
    "#         for i in range(len(features_combined)):\n",
    "#             correlation, _ = spearmanr(liked_movie_features, features_combined[i])\n",
    "#             distance = 1 - correlation  # Convert correlation to distance\n",
    "#             similarity = 1 / (1 + distance)  # Convert distance to similarity score\n",
    "#             similarity_scores.append((i, correlation, distance, similarity))\n",
    "\n",
    "#         # Sort by highest correlation (most similar)\n",
    "#         similarity_scores.sort(key=lambda x: -x[1])\n",
    "\n",
    "#         print(f\"Anime similar to '{anime_liked}' based on Spearman Correlation:\\n\")\n",
    "#         for i in range(15):\n",
    "#             anime_name = get_title_from_index(similarity_scores[i][0])\n",
    "#             correlation = similarity_scores[i][1]\n",
    "#             distance = similarity_scores[i][2]\n",
    "#             similarity = similarity_scores[i][3]\n",
    "#             print(f\"{anime_name} - Correlation: {correlation:.4f}, Distance: {distance:.4f}, Similarity: {similarity:.4f}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error: {e}\")\n",
    "\n",
    "# # Call the function\n",
    "# find_similar_anime_spearman(anime_liked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
